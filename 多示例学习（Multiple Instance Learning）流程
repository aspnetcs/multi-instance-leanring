多示例学习（Multiple Instance Learning）

mjiansun 2019-08-01 11:00:29  1956  收藏 4
分类专栏： 机器学习
版权
多示例问题 （Multiple Instance Problem）
我们考虑这样一种训练数据，这个数据是有标记的，标记只有两个类别，正和负。但这一次标记的目标不是一个样本，而是一个数据包（bag)。某一个或者几个数据合在一起叫做一个bag，每个bag有自己的标记。当一个bag的标记为负时，这个bag里面所有样本的标记都是负的。当一个bag的标记为正时，这个bag里面至少有一个样本的标记为正。 我们的目标是学习得到一个分类器，使得对新输入的样本，可以给出它的正负标记。这样的一类问题就是多示例问题。

 

这个问题在实际的应用中非常常见，比如说，方校长建长城的时候，他要列举一些违禁词汇不让大家搜索，他觉得一个一个输入太麻烦了，于是可以找来一些黄色或者反动的网站，直接作为正样本包：网站中的词汇总有一个是违禁的。然后拿健康向上的人民日报网页作为负样本包：里面的词汇没有一个是违禁的。又比如做检测问题，标记训练图片样本的时候需要给出一个矩形框指明目标的位置，有可能标的不够准确，导致不同的样本之间对不齐，这时候可以将标记的矩形框做一些局部扰动得到一些新的矩形框，将它们一起看成一个bag，其中总有一个是最佳的正样本，也就是标记为正。而取一张没有目标的图片，作为负样本包：无论在里面怎么截取图片，都是负样本。

 

求解方法
关于多示例问题怎么求解，假如说所有的样本标记都已经知道了，那就是一个监督学习的问题了，用SVM，adaboost之类的都可以做。现在的困难是，有很多样本的标记我们不知道。对于负样本包来说就无所谓了，里面每个样本那都是负标记，这个是明确的。问题出在正样本包上面，每个正样本包里只能保证有一个是正样本，其他的是正是负就不知道了，关键是到底是哪个样本是正的呢？这个也是不清楚的。

 

解决这个问题的方法其实挺直接的：迭代优化（alternative optimization)。也就是说，我们先假设已经知道了所有样本的标记(即正样本包里的所有示例都标志为正的标签，负样本里的示例都是负的标签)，那么就可以通过某种监督学习的方法得到一个分类模型，通过这个模型我们可以对每个训练样本进行预测，然后更新它们的标记，我们又可以拿这一次新得到的标记重新训练分类模型了。所以整个优化过程分为两部分：监督学习，标记更新。

 

这里还有一些地方需要注意：

第一点， 训练监督学习的模型的时候，只从正样本包里挑选被预测的“最像正确”(也就是分类得分最高)的那一个，正样本包里面其他的样本，不管预测出来是正的还是负的都不要了。这是因为，其实多示例的问题也可以描述为，正样本包里面“最正确”的一个样本标记是正的，跟其他样本无关。所以，这种选择策略恰恰是符合问题定义的。

第二点，如果负样本足够多的话，可以只挑选每个负样本包里面被预测“最像正确"的一个样本作为负样本进行训练，这样子的负样本也叫做hard sample或者most violated sample。实践上来说，它们对于模型快速收敛是最有效的。

那么下面给出一个简单的流程图：
已知条件

输入：数据矩阵, 包标记，包与样本的关系

输出： 分类函数 f

将每个标记包j中的样本初始化为包的标记，初始化集合U为空，将所有样本加入样本集U

 

重复下面的过程

    取的样本的数据以及标记训练得到一个分类函数f

    利用f预测所有样本的标记

    清空U

    对于每个正标记包，选取f预测得分最高的样本加入集合U

    对于每个负标记包，选取f预测得分最高的样本加入集合U（或者取较高的某些样本，也可以取全部样本都加入U，这取决于负  样本是否充足)

直到满足结束条件

 

返回f
