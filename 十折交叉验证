十折交叉验证

rocling 2019-06-22 16:27:21  3436  收藏 3
分类专栏： 人工智能
版权
交叉验证主要分成以下几类：
1）k-folder cross-validation:k个子集，每个子集均做一次测试集，其余的作为训练集。交叉验证重复k次，每次选择一个子集作为测试集，并将k次的平均交叉验证识别正确率作为结果。优点：所有的样本都被作为了训练集和测试集，每个样本都被验证一次。10-folder通常被使用。
2）K * 2 folder cross-validation是k-folder cross-validation的一个变体，对每一个folder，都平均分成两个集合s0,s1，我们先在集合s0训练用s1测试，然后用s1训练s0测试。优点是：测试和训练集都足够大，每一个个样本都被作为训练集和测试集。一般使用k=10
3)least-one-out cross-validation(loocv)假设dataset中有n个样本，那LOOCV也就是n-CV，意思是每个样本单独作为一次测试集，剩余n-1个样本则做为训练集。
优点：
1）每一回合中几乎所有的样本皆用于训练model，因此最接近母体样本的分布，估测所得的generalization error比较可靠。
2）实验过程中没有随机因素会影响实验数据，确保实验过程是可以被复制的。但LOOCV的缺点则是计算成本高，为需要建立的models数量与总样本数量相同，当总样本数量相当多时，LOOCV在实作上便有困难，除非每次训练model的速度很快，或是可以用平行化计算减少计算所需的时间。

-------十折交叉验证：10-fold cross validation-------
英文名叫做10-fold cross-validation，用来测试算法准确性。是常用的测试方法。将数据集分成十分，轮流将其中9份作为训练数据，1份作为测试数据，进行试验。每次试验都会得出相应的正确率（或差错率）。10次的结果的正确率（或差错率）的平均值作为对算法精度的估计，一般还需要进行多次10折交叉验证（例如10次10折交叉验证），再求其均值，作为对算法准确性的估计。
之所以选择将数据集分为10份，是因为通过利用大量数据集、使用不同学习技术进行的大量试验，表明10折是获得最好误差估计的恰当选择，而且也有一些理论根据可以证明这一点。但这并非最终诊断，争议仍然存在。而且似乎5折或者20折与10折所得出的结果也相差无几。
————————————————
版权声明：本文为CSDN博主「rocling」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/rocling/java/article/details/93335773
